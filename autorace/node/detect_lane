#!/usr/bin/env python
# -*- coding: utf-8 -*-

import rospy
import numpy as np
import cv2
from cv_bridge import CvBridge
from std_msgs.msg import UInt8, Float64
from sensor_msgs.msg import Image, CompressedImage
from dynamic_reconfigure.server import Server
from turtlebot3_autorace_detect.cfg import DetectLaneParamsConfig

class DetectLane():
    def __init__(self):
        self.hue_white_l = rospy.get_param("~lane/white/hue_l", 0)
        self.hue_white_h = rospy.get_param("~lane/white/hue_h", 25)
        self.saturation_white_l = rospy.get_param("~lane/white/saturation_l", 0)
        self.saturation_white_h = rospy.get_param("~lane/white/saturation_h", 36)
        self.lightness_white_l = rospy.get_param("~lane/white/lightness_l", 180)
        self.lightness_white_h = rospy.get_param("~lane/white/lightness_h", 255)

        self.hue_whiteL_l = rospy.get_param("~lane/whiteL/hue_l", 0)
        self.hue_whiteL_h = rospy.get_param("~lane/whiteL/hue_h", 25)
        self.saturation_whiteL_l = rospy.get_param("~lane/whiteL/saturation_l", 0)
        self.saturation_whiteL_h = rospy.get_param("~lane/whiteL/saturation_h", 36)
        self.lightness_whiteL_l = rospy.get_param("~lane/whiteL/lightness_l", 180)
        self.lightness_whiteL_h = rospy.get_param("~lane/whiteL/lightness_h", 255)

        self.is_calibration_mode = rospy.get_param("~is_detection_calibration_mode", False)
        if self.is_calibration_mode == True:
            srv_detect_lane = Server(DetectLaneParamsConfig, self.cbGetDetectLaneParam)

        self.sub_image_type = "raw"         # you can choose image type "compressed", "raw"
        self.pub_image_type = "compressed"  # you can choose image type "compressed", "raw"

        if self.sub_image_type == "compressed":
            # subscribes compressed image
            self.sub_image_original = rospy.Subscriber('/detect/image_input/compressed', CompressedImage, self.cbFindLane, queue_size = 1)
        elif self.sub_image_type == "raw":
            # subscribes raw image
            self.sub_image_original = rospy.Subscriber('/detect/image_input', Image, self.cbFindLane, queue_size = 1)

        # topic per frame di output
        #if self.pub_image_type == "compressed":
            # publishes lane image in compressed type
        #    self.pub_image_lane = rospy.Publisher('/detect/image_output/compressed', CompressedImage, queue_size = 1)
        #elif self.pub_image_type == "raw":
            # publishes lane image in raw type
        #    self.pub_image_lane = rospy.Publisher('/detect/image_output', Image, queue_size = 1)

        self.cvBridge = CvBridge()

    def cbGetDetectLaneParam(self, config, level):
        rospy.loginfo("[Detect Lane] Detect Lane Calibration Parameter reconfigured to")
        rospy.loginfo("hue_white_l : %d", config.hue_white_l)
        rospy.loginfo("hue_white_h : %d", config.hue_white_h)
        rospy.loginfo("saturation_white_l : %d", config.saturation_white_l)
        rospy.loginfo("saturation_white_h : %d", config.saturation_white_h)
        rospy.loginfo("lightness_white_l : %d", config.lightness_white_l)
        rospy.loginfo("lightness_white_h : %d", config.lightness_white_h)
        rospy.loginfo("hue_whiteL_l : %d", config.hue_whiteL_l)
        rospy.loginfo("hue_whiteL_h : %d", config.hue_whiteL_h)
        rospy.loginfo("saturation_whiteL_l : %d", config.saturation_whiteL_l)
        rospy.loginfo("saturation_whiteL_h : %d", config.saturation_whiteL_h)
        rospy.loginfo("lightness_whiteL_l : %d", config.lightness_whiteL_l)
        rospy.loginfo("lightness_whiteL_h : %d", config.lightness_whiteL_h)

        self.hue_white_l = config.hue_white_l
        self.hue_white_h = config.hue_white_h
        self.saturation_white_l = config.saturation_white_l
        self.saturation_white_h = config.saturation_white_h
        self.lightness_white_l = config.lightness_white_l
        self.lightness_white_h = config.lightness_white_h

        self.hue_whiteL_l = config.hue_whiteL_l
        self.hue_whiteL_h = config.hue_whiteL_h
        self.saturation_whiteL_l = config.saturation_whiteL_l
        self.saturation_whiteL_h = config.saturation_whiteL_h
        self.lightness_whiteL_l = config.lightness_whiteL_l
        self.lightness_whiteL_h = config.lightness_whiteL_h

        return config

    def cbFindLane(self, image_msg):

        if self.sub_image_type == "compressed":
            # converte il messaggio dal topic in un oggetto mat di opencv
            np_arr = np.fromstring(image_msg.data, np.uint8)
            cv_image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)

        elif self.sub_image_type == "raw":
            cv_image = self.cvBridge.imgmsg_to_cv2(image_msg, "bgr8")

        # converte scala di grigio
        gray = cv2.cvtColor(cv_image,cv2.COLOR_BGR2GRAY)
        rows , cols  = gray.shape
        # ciclo per eliminare i bordi neri della homography dal frame
        for i in range(rows):
            for j in range(cols):
                if gray[i][j] in range(0,5):
                    gray[i][j] = 87

        # threshold per individuare le linee dell'immagine
        ret,gray = cv2.threshold(gray,115,138,cv2.THRESH_BINARY)
        element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))
        done = False
        size = np.size(gray)
        skel = np.zeros(gray.shape, np.uint8)

        # ciclo per applicare un filtro di scheletrizzazione per affinare le linee
        while not done:
            eroded = cv2.erode(gray, element)
            temp = cv2.dilate(eroded, element)
            temp = cv2.subtract(gray, temp)
            skel = cv2.bitwise_or(skel, temp)
            gray = eroded.copy()
            zeroes = size - cv2.countNonZero(gray)
            if zeroes == size:
                done = True

        # filtro gaussiano per aumentare il numero di segmanti usati per la HoughLinesP
        gray = skel
        kernel_size = 1
        blur_gray = cv2.GaussianBlur(gray,(kernel_size, kernel_size),0)

        # decomentare per avere piÃ¹ segmenti
        #low_threshold = 6
        #high_threshold = 14
        #edges = cv2.Canny(blur_gray, low_threshold, high_threshold)

        rho = 1  # distance resolution in pixels of the Hough grid
        theta = np.pi / 180  # angular resolution in radians of the Hough grid
        threshold = 15  # minimum number of votes (intersections in Hough grid cell)
        min_line_length = 50  # minimum number of pixels making up a line
        max_line_gap = 40  # maximum gap in pixels between connectable line segments
        line_image = np.copy(cv_image) * 0  # creating a blank to draw lines on

        # funzione probabilistica per fare la line detection
        lines = cv2.HoughLinesP(gray, rho, theta, threshold, np.array([]), min_line_length, max_line_gap)

        x_min_avg = 0
        x_max_avg = 0
        y_min = 0

        y_max = np.shape(gray)[1]
        i = 0
        # disegno delle line blu
        for line in lines:
            for x1,y1,x2,y2 in line:
                cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0))
                x_min_avg = x_min_avg + x1
                x_max_avg = x_max_avg + x2
                i += 1
        # calcolo della line centrale in base hai punti trovati nella HoughLinesP
        x_min_avg = x_min_avg/i
        x_max_avg = x_max_avg/i

        destra = 0
        sinistra = 0
        x_min_avg_dx = 0
        x_max_avg_dx = 0
        x_min_avg_sx = 0
        x_max_avg_sx = 0

        # calcolo pesato della linea gialla per essere al centro
        for line in lines:
            for x1,y1,x2,y2 in line:
                if x1 > x_min_avg:
                    destra += 1
                    x_min_avg_dx = x_min_avg_dx + x1
                    x_max_avg_dx = x_max_avg_dx + x2
                else:
                    sinistra +=1
                    x_min_avg_sx = x_min_avg_sx + x1
                    x_max_avg_sx = x_max_avg_sx + x2
        x_min_avg_dx = x_min_avg_dx/destra
        x_max_avg_dx = x_max_avg_dx/destra
        x_min_avg_sx = x_min_avg_sx/sinistra
        x_max_avg_sx = x_max_avg_sx/sinistra

        x_min_avg = (x_min_avg_dx + x_min_avg_sx)/2
        x_max_avg = (x_max_avg_dx + x_max_avg_sx)/2

        # disegno della linea gialla
        cv2.line(line_image,(x_min_avg,y_min),(x_max_avg,y_max),(0,255,255))
        # svrappone le linee al frame
        final = cv2.addWeighted(cv_image, 0.8, line_image, 1, 0)
        cv2.namedWindow('linee edge', cv2.WINDOW_NORMAL)
        cv2.resizeWindow('linee edge', 600, 600)
        cv2.imshow("linee edge", final)
        # esce dal ciclo di acqusizione
        if cv2.waitKey(1) & 0xFF == ord('q'):
            rospy.signal_shutdown('Quit')

        # pubblicazione sui topic per visualizzare la detect.
        #if self.pub_image_type == "compressed":
        #    self.pub_image_lane.publish(self.cvBridge.cv2_to_compressed_imgmsg(final, "jpg"))

        #elif self.pub_image_type == "raw":
        #    self.pub_image_lane.publish(self.cvBridge.cv2_to_imgmsg(final, "bgr8"))

    def main(self):
        rospy.spin()

if __name__ == '__main__':
    rospy.init_node('detect_lane')
    node = DetectLane()
    node.main()
